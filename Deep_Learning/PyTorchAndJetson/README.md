### Using PyTorch 

PyTorch is a framework of libraries that expand the power of Python language across the NN field (see [here](https://pytorch.org/) for more information). Tensorflow-Keras framework (which we are talking about in another branch) has unfortunately some difficulty on *freezing* NN structure and weights for transforming it in a deployment form. A deployment form of a NN is cleaned by other training parameters except weights. So it is ready for inference. A deployment form can be translated in Open Neural Network Exchange (ONNX) format, and interchanged between frameworks and hardware. Using PyTorch this operation is easier. When we have a deployment version we can transfer NN inside hardware specialized as Jetson Nano (with CUDA). That operation should be useful for hobbyists who want utilize NN deep learning structure for any advanced application. PyTorch too has some limitation; for example it can describe a deep learning structure not just by a list of layers, but also defining a forward function. In other world, the export of network (.pth)  can be not enough to be translated to ONNX format (.onnx). The PyThorch utility needs to simulate a forward phase (just a single sample) for recognizing the network structure and producing the export in ONNX format. 

- [MNISTtest](MNISTtest) The directory contains a software for MNIST  deep learning training/inference
- [PyTUtilities](PyTUtilities)  Some scripts 